{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faa65b59",
   "metadata": {},
   "source": [
    "# Introduction to spatial data analysis with geopandas\n",
    "\n",
    "Now as we have learned how to create and represent geographic data in Python using `shapely` objects, we will continue and use [geopandas](https://geopandas.org/) [^geopandas] as our main tool for spatial data analysis. Geopandas extends the capacities of pandas (which we covered in the Part I of the book) with geospatial operations. The main data structures in geopandas are `GeoSeries` and `GeoDataFrame` which extend the capabilities of `Series` and `DataFrames` from pandas. This means that we can use many familiar methods from pandas also when working with geopandas and spatial features. A `GeoDataFrame` is basically a `pandas.DataFrame` that contains one column for geometries. The geometry column is a `GeoSeries` which contains the geometries  as `shapely` objects (points, lines, polygons, multipolygons etc.). \n",
    "\n",
    "## Getting started with geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b88e99",
   "metadata": {},
   "source": [
    "![_**Figure 6.1**. Geometry column in a GeoDataFrame._](../img/geodataframe.png)\n",
    "\n",
    "_**Figure 6.1**. Geometry column in a GeoDataFrame._\n",
    "\n",
    "Similar to importing import pandas as `pd`, we will import geopandas as `gpd`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc0c3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4ee3e0",
   "metadata": {},
   "source": [
    "## Reading a Shapefile\n",
    "\n",
    "Esri Shapefile is the default file format when reading in data usign geopandas, so we only need to pass the file path in order to read in our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606cfa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "input_folder = Path(\"../data/NLS\")\n",
    "fp = input_folder / \"m_L4132R_p.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db42e539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file using gpd.read_file()\n",
    "data = gpd.read_file(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c82314a",
   "metadata": {},
   "source": [
    "Let's check the data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb84a0d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2028763e",
   "metadata": {},
   "source": [
    "Here we see that our `data` -variable is a `GeoDataFrame`. GeoDataFrame extends the functionalities of\n",
    "`pandas.DataFrame` in a way that it is possible to handle spatial data using similar approaches and datastructures as in pandas (hence the name geopandas). \n",
    "\n",
    "Let's check the first rows of data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f2c58f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991b007d",
   "metadata": {},
   "source": [
    "- Check all column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c7763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c70bbe8",
   "metadata": {},
   "source": [
    "As you might guess, the column names are in Finnish.\n",
    "Let's select only the useful columns and rename them into English:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0506726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"RYHMA\", \"LUOKKA\", \"geometry\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8c4ac3",
   "metadata": {},
   "source": [
    "Define new column names in a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070c6753",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = {\"RYHMA\": \"GROUP\", \"LUOKKA\": \"CLASS\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4380f11e",
   "metadata": {},
   "source": [
    "Rename:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48fd7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns=colnames, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebcf22e",
   "metadata": {},
   "source": [
    "Check the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1cb388",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42d8a0a",
   "metadata": {},
   "source": [
    "#### Question 6.2\n",
    "\n",
    "Figure out the following information from our input data using your pandas skills:\n",
    "    \n",
    "- Number of rows?\n",
    "- Number of classes?\n",
    "- Number of groups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3101fec",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# You can use this cell to enter your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8e9b76",
   "metadata": {
    "tags": [
     "remove_book_cell",
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Solution \n",
    "\n",
    "print(\"Number of rows\", len(data[\"CLASS\"]))\n",
    "print(\"Number of classes\", data[\"CLASS\"].nunique())\n",
    "print(\"Number of groups\", data[\"GROUP\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe464d8",
   "metadata": {},
   "source": [
    "It is always a good idea to explore your data also on a map. Creating a simple map from a `GeoDataFrame` is really easy. You can use ``.plot()`` -function from geopandas that **creates a map based on the geometries of the data**. Geopandas actually uses matplotlib for plotting which we introduced in Part 1 of this book. Let's try it out, and do a quick visualization of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb617c9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dd1f34",
   "metadata": {},
   "source": [
    "Voil√°! As we can see, it is really easy to produce a map out of your geospatial data with `geopandas`. *If you are living in the Helsinki region in Finland, you might recognize the shapes plotted on the map!*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861f9bff",
   "metadata": {},
   "source": [
    "## Geometries in geopandas\n",
    "\n",
    "Geopandas takes advantage of Shapely's geometric objects. Geometries are stored in a column called `geometry` that is a default column name for storing geometric information in geopandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e51478",
   "metadata": {},
   "source": [
    "Let's print the first 5 rows of the column 'geometry':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaf22f4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data[\"geometry\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7b7cce",
   "metadata": {},
   "source": [
    "As we can see the `geometry` column contains familiar looking values, namely shapely `Polygon` -objects. Since the spatial data is stored as shapely objects, it is possible to use shapely methods when dealing with geometries in geopandas. Also,  all `pandas` methods are directly available in `geopandas` without the need to import `pandas` separately. Let's have a closer look at the polygons and try to apply some of the methods we are already familiar with. Let's start by checking the area of the first polygon in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582806b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the geometry on the first row of data\n",
    "data.at[0, \"geometry\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10be3739",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Print information about the area\n",
    "print(\"Area:\", round(data.at[0, \"geometry\"].area, 0), \"square meters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf57bb9",
   "metadata": {},
   "source": [
    "Geodataframes and geoseries have an attribute `area` which we can use for accessing the area for each feature at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc10af80",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ea8f54",
   "metadata": {},
   "source": [
    "Let's next create a new column into our GeoDataFrame where we calculate and store the areas of individual polygons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1838753",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a new column called 'area'\n",
    "data[\"area\"] = data.area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0490560a",
   "metadata": {},
   "source": [
    "Check the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b08836",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"area\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3856657",
   "metadata": {},
   "source": [
    "Let's check what is the `min`, `max` and `mean` of those areas using `pandas` functions introduced in Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa81e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum area\n",
    "round(data[\"area\"].max(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541df631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum area\n",
    "round(data[\"area\"].min(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "face2d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average area\n",
    "round(data[\"area\"].mean(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c064a1",
   "metadata": {},
   "source": [
    "## Writing data into a file\n",
    "\n",
    "It is possible to export GeoDataFrames into various data formats using the [to_file()](http://geopandas.org/io.html#writing-spatial-data) method. In our case, we want to export subsets of the data into Shapefiles (one file for each feature class).\n",
    "\n",
    "Let's first select one class (class number `36200`, \"Lake water\") from the data as a new GeoDataFrame:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37b9c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a class\n",
    "selection = data.loc[data[\"CLASS\"] == 36200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0d873e",
   "metadata": {},
   "source": [
    "Check the selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5803bf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540f9cb1",
   "metadata": {},
   "source": [
    "Write this layer into a new Shapefile using the `gpd.to_file()` -function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d9eacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a output path for the data\n",
    "output_folder = Path(\"results\")\n",
    "\n",
    "if not output_folder.exists():\n",
    "    output_folder.mkdir()\n",
    "\n",
    "output_fp = output_folder / \"Class_36200.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d317f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write those rows into a new file (the default output file format is Shapefile)\n",
    "selection.to_file(output_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bd2bc1",
   "metadata": {},
   "source": [
    "#### Question 6.3\n",
    "\n",
    "Read the output Shapefile in a new geodataframe, and check that the data looks ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7325ea",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Use this cell to enter your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c947fbba",
   "metadata": {
    "tags": [
     "remove_book_cell",
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "temp = gpd.read_file(output_fp)\n",
    "\n",
    "# Check first rows\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64223fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "# You can also plot the data for a visual check\n",
    "temp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37edc293",
   "metadata": {},
   "source": [
    "## Grouping the GeoDataFrame\n",
    "\n",
    "Next we will automate the file export task. we will group the data based on column `CLASS` and export a shapefile for each class. Here we can use the `.groupby()` method from `pandas` and apply it on our `GeoDataFrame`. The function groups data based on values on selected column(s).  We will want to group the data by distinct classes. Before continuing, let's check the structure of our data from the first rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5e0e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bd94d1",
   "metadata": {},
   "source": [
    "The `CLASS` column in the data contains information about different land use types represeted with class codes. We can also check all unique values in that column and the number of unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5393c0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Print all unique values in the column\n",
    "data[\"CLASS\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c86cd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the number of unique values\n",
    "data[\"CLASS\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351bad7b",
   "metadata": {},
   "source": [
    "Now we can group the data into 20 distinct groups based on the land use class code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c3c32a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Group the data by class\n",
    "grouped = data.groupby(\"CLASS\")\n",
    "\n",
    "# Let's see what we have\n",
    "len(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d4566a",
   "metadata": {},
   "source": [
    "The grouped object is similar to a list of keys and values in a dictionary and we can access, for example, information about the group keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61bd5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.groups.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6addc4df",
   "metadata": {},
   "source": [
    "As it should be, the group keys are unique values from the column by which we grouped the dataframe. Let's also check how many rows of data belongs to each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6304a48",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Iterate over the grouped object\n",
    "for key, group in grouped:\n",
    "\n",
    "    # Check how many rows each group has:\n",
    "    print(\"Terrain class:\", key)\n",
    "    print(\"Number of rows:\", len(group), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70edfee7",
   "metadata": {},
   "source": [
    "There are, for example, 56 lake polygons (class number 36200) in the input data. To get a better sense of the data structure, we can also check how the _last_ group looks like (because at this point, we have the variables in memory from the last iteration of the for-loop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1269f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "group.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83203d11",
   "metadata": {},
   "source": [
    "Notice that the index numbers refer to the row numbers in the original data. Check also the data type of the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc63f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d76881",
   "metadata": {},
   "source": [
    "At this point, the data are now grouped into separate GeoDataFrames by class. From here, we can save them into separate files.\n",
    "\n",
    "### Saving multiple output files\n",
    "\n",
    "Let's export each class into a separate Shapefile. While doing this, we also want to create unique filenames for each class.\n",
    "\n",
    "When looping over the grouped object, information about the class is stored in the variable `key`, and we can use this information for creating new variable names inside the for-loop. For example, we want to name the shapefile containing lake polygons as \"terrain_36200.shp\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2d4c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine output directory\n",
    "output_folder = Path(\"../data\")\n",
    "\n",
    "# Create a new folder called 'Results'\n",
    "result_folder = output_folder / \"Results\"\n",
    "\n",
    "# Check if the folder exists already\n",
    "if not result_folder.exists():\n",
    "\n",
    "    print(\"Creating a folder for the results..\")\n",
    "    # If it does not exist, create one\n",
    "    result_folder.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030083c4",
   "metadata": {},
   "source": [
    "At this point, you can go to the file browser and check that the new folder was created successfully. Finally, we will iterate over groups, create a file name, and save each group to a separate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff4887f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Iterate over the groups\n",
    "for key, group in grouped:\n",
    "    # Format the filename\n",
    "    output_name = Path(\"terrain_{}.shp\".format(key))\n",
    "\n",
    "    # Print information about the process\n",
    "    print(\"Saving file\", output_name.name)\n",
    "\n",
    "    # Create an output path\n",
    "    outpath = result_folder / output_name\n",
    "\n",
    "    # Export the data\n",
    "    group.to_file(outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c69cda4",
   "metadata": {},
   "source": [
    "Excellent! Now we have saved those individual classes into separate files and named the file according to the class name. Imagine how long time it would have taken to do the same thing manually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56a820f",
   "metadata": {},
   "source": [
    "### Save attributes to a text file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86c0952",
   "metadata": {},
   "source": [
    "We can also extract basic statistics from our geodataframe, and save this information as a text file. Let's summarize the total area of each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da8c2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8cd9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_info = grouped.area.sum().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae37c8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0e7e4a",
   "metadata": {},
   "source": [
    "Save area info to csv using pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b41f928",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Create an output path\n",
    "area_info.to_csv(result_folder / \"terrain_class_areas.csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e930a43f",
   "metadata": {},
   "source": [
    "## Footnotes\n",
    "\n",
    "[^bounding_box]: <https://en.wikipedia.org/wiki/Minimum_bounding_box>\n",
    "[^box]: <https://shapely.readthedocs.io/en/stable/manual.html#shapely.geometry.box>\n",
    "[^geopandas]: <https://geopandas.org/>\n",
    "[^GEOS]: <https://trac.osgeo.org/geos>\n",
    "[^NLS_topodata]: <https://www.maanmittauslaitos.fi/en/maps-and-spatial-data/expert-users/product-descriptions/topographic-database>\n",
    "[^NLS_lisence]: <https://www.maanmittauslaitos.fi/en/opendata-licence-cc40>\n",
    "[^OGC_sfa]: <https://www.ogc.org/standards/sfa>\n",
    "[^paituli]: <https://avaa.tdata.fi/web/paituli/latauspalvelu>\n",
    "[^polygon]: <https://shapely.readthedocs.io/en/stable/manual.html#polygons>\n",
    "[^PostGIS]: <https://postgis.net/>\n",
    "[^QGIS]: <http://www.qgis.org/en/site/>\n",
    "[^shapely]: <https://shapely.readthedocs.io/en/stable/manual.html>\n",
    "[^topodata_fair]: <https://etsin.fairdata.fi/dataset/5023ecc7-914a-4494-9e32-d0a39d3b56ae>\n",
    "[^WKT]: <https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
